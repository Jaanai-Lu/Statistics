特征选择对于高维数据处理和分析具有重大价值和意义。
特征选择的好处：
1. 大数据时代，数据挖掘和机器学习的一大挑战就是维度灾难，特征选择是缓解维度灾难的一种有效方法。
2. 通过特征选择，可以建立有效的模型，避免过拟合，提升模型性能。
3. 对高维数据做处理和分析时，使用特征选择，可以减少内存的空间和降低算力成本。
4. 做特征选择，可以降低数据获取的难度和成本，也有利于数据的理解。
总之，我们可以从数据的整个链，即数据的获取，数据存储，数据处理，数据分析和挖掘，数据应用来思考特征选择所带来的价值和意义。
你会发现，对数据做特征选择，对于数据链的各个环节都有益处。

特征选择是什么？
特征选择是针对所要解决的特定问题从原始特征集选择或者搜索到一个最佳的特征子集。
如何得到这个最佳特征子集，那就是特征选择的方法或者算法要做的事情。

怎么做特征选择？
前面已经提到了，通过特征选择方法或者算法从数据的原始特征集中获得最佳的特征子集。
如何来度量这个“最佳”？
纵观前人所做的事情，要么从特征自身的角度入手分析，俗话说，“打铁还需自身硬”，若是特征本身就具有很强的信息，这对我们解决问题就是一种价值；
要么从特征集的关系以及特征集与目标问题之间的关系来寻求一种最佳组合。
鉴于此，前人把特征选择的方法划分为三类型：Filter方法、Wrapper方法、Embedded方法。
