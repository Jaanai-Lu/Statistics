Linear Mixde Model, 简称LMM, 称之为线性混合模型。
线性混合模型是在一般线性模型的基础上扩展而来，在回归公式中同时包含了以下两种效应：
1. fixed-effects， 固定效应
2. random efffects，随机效应

当然两种模型的本质并不是体现在回归公式中自变量的多少，而在于自变量的类别
在一般线性模型中，其自变量全部为固定效应自变量，而线性混合模型中，除了固定效应自变量外，还包含了随机效应自变量。

所以关键之处在于判定自变量的类别，如果一个自变量的所有类别在抽样的数据集中全部包含，则将该变量作为固定效应
比如性别，只要抽样的数据中同时包含了两种性别，就可以将性别作为固定效应自变量；
如果一个自变量在抽样的数据集中的结果只是从总体中随机抽样的结果，那么需要作为随机效应自变量
简而言之，如果抽样数据集中的自变量可以包含该自变量的所有情况，则作为固定效应，如果只能代表总体的一部分，则作为随机效应。

在分析的时候，可以将自变量都作为固定效应自变量，然后用一般线性模型来进行处理，那么为何要引入随机效应自变量呢？

使用一般线性模型时，是需要满足以下3点假设的：
1. 正态性，因变量y符合正态分布
2. 独立性，不同类别y的观察值之间相互独立，相关系数为零
3. 方差齐性，不同类别y的方差相等

以性别这个分类变量为例，如果不同性别对应的因变量值有明显差异，也就是我们常说的数据分层，那么就不满足上述条件了
此时如果坚持使用一般线性模型来拟合所有样本，其参数估计值不再具有最小方差线性无偏性，回归系数的标准误差会被低估，利用回归方程得到的估计值也会过高。

对于分层明显的数据，一种解决方案就是将不同的层分开处理，比如性别分层，那么就将不同性别的数据分开，每一类单独处理，
但是这要求每一类包含的样本数据量要够多，而且分层因素的类别也不能太多，太多了处理起来也很麻烦。
另外一个解决方案就是更换模型，使用线性混合模型。

一般线性模型有3个前提条件，而线性混合模型只保留了其中的第一点，即因变量要符合正态分布，对于独立性和方差齐性不做要求，所以适用范围更加广泛。
对于一般线性模型，可以通过最小二乘法或者最大似然法来估算其参数，
对于线性混合模型，常用的参数估方法为约束性最大似然法restricted maximum likelihood，简称REML。
