library(pacman)
p_update()
p_load(tidyverse, klaR)
data("GermanCredit")
GermanCredit %>% as_tibble -> df
# DataExplorer包提供了一个快速仪表盘的生成，在工作目录中生成
p_load(DataExplorer)
create_report(df)
# 用dlookr对表格进行审视
p_load(dlookr)
diagnose(df) %>% arrange(types) %>% print(n = Inf)
# 还可以用skimr包，与上面的方法相比，它会自动对数据类型进行分类
p_load(skimr)
skim(df)
# 一个比较好的可视化方法，visdat包
p_load(visdat)
vis_dat(df)
# 数值型变量的分布观察（单变量数据分布）
plot_density(df)
# 因子型变量的分布观察（单变量数据分布）
plot_bar(df)
# 响应变量为因子变量，因子变量与所有连续变量（数值变量）的关系，用箱线图表示
plot_boxplot(df, by = 'credit_risk')
# 连续变量之间的关系，做相关性矩阵图：越椭圆越相关
plot_correlate(df)
# 如果连因子变量的相关性也想知道，就用下面这个函数，它会把所有因子变量都用one-hot编码转化为数值型变量，然后做一个大的相关分析矩阵
plot_correlation(df)
# 也可以设置type参数，得到一个专门分析连续变量的图
plot_correlation(df, type = 'c')
# 要想同时获得相关性的信息，首推PerformanceAnalytics包
p_load(PerformanceAnalytics)
df %>% select_if(is.numeric) %>% chart.Correlation() # 这个图只能看数值型变量的相互关系，能够同时观察分布、相关系数和显著性水平
# 经典的离群点检测法，是箱线图判断离群点的方法（统计学上称为Tukey’s fences），这是基于单变量的。
# 这个方法大家可以在维基查询到，网址为https://en.wikipedia.org/wiki/Outlier。
# 很多R包默认的方法都是基于这个规则的，并可以自动删除、替代、设为缺失值。 
# 发现离群点，要知道离群点背后的意义。
# 离群点的寻找，一方面是为了想办法消除离群点给数据带来的影响，从而让我们的机器学习方法具有更强的鲁棒性；
# 第二方面，其实可以找到这些离群值，然后对离群值进行一些详细的研究。
# 很多欺诈的案例都是通过寻找离群点找到的，因为存在欺诈行为的用户，他们的行为会跟正常的用户有显著的差异。 
# 应该明确的是，分类变量是不会有离群值的，只有数值型变量才有探索离群值的意义。
# 我们用dlookr的diagnose_outliers函数，来查看变量离群值的情况
diagnose_outlier(df)
# 回归方法对离群值是敏感的。不过我们可以对变量先进行中心化、标准化，从而减少离群值的影响。
# 如果想要得到整个数据质量报告，可以用下面这个函数
diagnose_report(df)
# 探索性数据分析的下一步，应该是数据预处理（特征工程）。一般来说，探索性数据分析需要知道以下几点：
# 数据的行列数，即多少样本、多少特征
# 数据特征的属性，即有多少分类变量、多少数值变量
# 数据特征的分布，数值变量要看密度分布，分类变量要看每个分类的占比
# 数据特征之间的相关性，是否存在共线性？解释变量与响应变量的关系是否明显？
# 数据是否存在缺失值？如果存在缺失值，能否解释缺失的原因？是随机缺失还是非随机缺失，或者是介于两者之间。
# 能否根据其自身的特征和缺失的特点进行插值，还是应该剔除？
# 数据特征中是否存在离群值？是什么原因导致的？是真实的还是因为错误的操作？为了进行建模，应该如何处理这些离群值？（中心化？取对数？还是直接踢出）
